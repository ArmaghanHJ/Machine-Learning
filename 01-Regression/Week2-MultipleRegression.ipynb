{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Week 2:\n",
    "\n",
    "&emsp;\n",
    "&emsp;\n",
    "&emsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;\n",
    "# Exercise 1-1\n",
    "# Regression Week 2: Multiple Regression (Interpretation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this first notebook is to explore multiple regression and feature engineering with existing sklearn Create functions.\n",
    "\n",
    "In this notebook you will use data on house sales in King County to predict prices using multiple regression. You will:\n",
    "* Use sklearn to do some feature engineering\n",
    "* Use built-in sklearn Create functions to compute the regression weights (coefficients/parameters)\n",
    "* Given the regression weights, predictors and outcome write a function to compute the Residual Sum of Squares\n",
    "* Look at coefficients and interpret their meanings\n",
    "* Evaluate multiple models via RSS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in house sales data\n",
    "\n",
    "Dataset is from house sales in King County, the region where the city of Seattle, WA is located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             date     price  bedrooms  bathrooms  sqft_living  \\\n",
       "0  7129300520  20141013T000000  221900.0         3       1.00         1180   \n",
       "1  6414100192  20141209T000000  538000.0         3       2.25         2570   \n",
       "2  5631500400  20150225T000000  180000.0         2       1.00          770   \n",
       "3  2487200875  20141209T000000  604000.0         4       3.00         1960   \n",
       "4  1954400510  20150218T000000  510000.0         3       2.00         1680   \n",
       "\n",
       "   sqft_lot  floors  waterfront  view     ...      grade  sqft_above  \\\n",
       "0      5650     1.0           0     0     ...          7        1180   \n",
       "1      7242     2.0           0     0     ...          7        2170   \n",
       "2     10000     1.0           0     0     ...          6         770   \n",
       "3      5000     1.0           0     0     ...          7        1050   \n",
       "4      8080     1.0           0     0     ...          8        1680   \n",
       "\n",
       "   sqft_basement  yr_built  yr_renovated  zipcode      lat     long  \\\n",
       "0              0      1955             0    98178  47.5112 -122.257   \n",
       "1            400      1951          1991    98125  47.7210 -122.319   \n",
       "2              0      1933             0    98028  47.7379 -122.233   \n",
       "3            910      1965             0    98136  47.5208 -122.393   \n",
       "4              0      1987             0    98074  47.6168 -122.045   \n",
       "\n",
       "   sqft_living15  sqft_lot15  \n",
       "0           1340        5650  \n",
       "1           1690        7639  \n",
       "2           2720        8062  \n",
       "3           1360        5000  \n",
       "4           1800        7503  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtype_dict = {'bathrooms':float, 'waterfront':int, 'sqft_above':int, 'sqft_living15':float, 'grade':int, 'yr_renovated':int, 'price':float, 'bedrooms':float, 'zipcode':str, 'long':float, 'sqft_lot15':float, 'sqft_living':float, 'floors':str, 'condition':int, 'lat':float, 'date':str, 'sqft_basement':int, 'yr_built':int, 'id':str, 'sqft_lot':int, 'view':int}\n",
    "\n",
    "sales = pd.read_csv(\"data/week2_kc_house_data.csv\")\n",
    "sales.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len Sales: 21613\n"
     ]
    }
   ],
   "source": [
    "print('len Sales: %d'%(len(sales)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data into training and testing.\n",
    "* Split \n",
    "    \n",
    "        80% train data and \n",
    "\n",
    "        20% test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len Train: 17290\n",
      "len Test: 4323\n"
     ]
    }
   ],
   "source": [
    "train_data,test_data = train_test_split(sales,test_size=0.2)\n",
    "print('len Train: %d\\nlen Test: %d'%(len(train_data),len(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning a multiple regression model\n",
    "Recall we can use the following code to learn a multiple regression model predicting 'price' based on the following features:\n",
    "example_features = ['sqft_living', 'bedrooms', 'bathrooms'] on training data with the following code:\n",
    "\n",
    "(Aside: We set validation_set = None to ensure that the results are always the same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_features = ['sqft_living', 'bedrooms', 'bathrooms']\n",
    "\n",
    "example_model = linear_model.LinearRegression()\n",
    "example_model.fit(train_data[example_features],train_data['price'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have fitted the model we can extract the regression weights (coefficients) as an sklearn as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   312.28759548 -63374.36308577   6893.18662492]\n"
     ]
    }
   ],
   "source": [
    "example_weight_summary = example_model.coef_\n",
    "print(example_weight_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Predictions\n",
    "\n",
    "In the gradient descent notebook we use numpy to do our regression. In this book we will use existing sklearn Create functions to analyze multiple regressions. \n",
    "\n",
    "Recall that once a model is built we can use the .predict() function to find the predicted values for data we pass. For example using the example model above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1038520.9319986172\n"
     ]
    }
   ],
   "source": [
    "example_predictions = example_model.predict(train_data[example_features])\n",
    "\n",
    "print(example_predictions[0]) # should be 271789.505878"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute RSS\n",
    "\n",
    "Now that we can make predictions given the model, let's write a function to compute the RSS of the model. Complete the function below to calculate RSS given the model, data, and the outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_residual_sum_of_squares(model, data, m_features, outcome):\n",
    "    # First get the predictions\n",
    "    predictions = model.predict(data[m_features])\n",
    "    \n",
    "    # Then compute the residuals/errors\n",
    "    residuals_errors = outcome - predictions\n",
    "\n",
    "    # Then square and add them up\n",
    "    residuals_errors_square = residuals_errors*residuals_errors\n",
    "    RSS = residuals_errors_square.sum()\n",
    "\n",
    "    return(RSS)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your function by computing the RSS on TEST data for the example model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "303947419523376.2\n"
     ]
    }
   ],
   "source": [
    "rss_example_train = get_residual_sum_of_squares(example_model, test_data, example_features, test_data['price'])\n",
    "print(rss_example_train) # should be 2.7376153833e+14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create some new features\n",
    "\n",
    "Although we often think of multiple regression as including multiple different features (e.g. # of bedrooms, squarefeet, and # of bathrooms) but we can also consider transformations of existing features e.g. the log of the squarefeet or even \"interaction\" features such as the product of bedrooms and bathrooms.\n",
    "\n",
    "\n",
    "You will use the logarithm function to create a new feature. so first you should import it from the math library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next create the following 4 new features as column in both TEST and TRAIN data:\n",
    "* bedrooms_squared = bedrooms\\*bedrooms\n",
    "* bed_bath_rooms = bedrooms\\*bathrooms\n",
    "* log_sqft_living = log(sqft_living)\n",
    "* lat_plus_long = lat + long \n",
    "As an example here's the first one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "train_data['bedrooms_squared'] = train_data['bedrooms'].apply(lambda x: x**2)\n",
    "test_data['bedrooms_squared'] = test_data['bedrooms'].apply(lambda x: x**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    }
   ],
   "source": [
    "# create the remaining 3 features in both TEST and TRAIN data\n",
    "\n",
    "# bed_bath_rooms = bedrooms*bathrooms\n",
    "train_data['bed_bath_rooms'] = train_data['bedrooms']*train_data['bathrooms']\n",
    "test_data['bed_bath_rooms'] = test_data['bedrooms']*test_data['bathrooms']\n",
    "\n",
    "# log_sqft_living = log(sqft_living)\n",
    "train_data['log_sqft_living'] = train_data['sqft_living'].apply(lambda x: log(x))\n",
    "test_data['log_sqft_living'] = test_data['sqft_living'].apply(lambda x: log(x))\n",
    "\n",
    "# lat_plus_long = lat + long As an example here's the first one:\n",
    "train_data['lat_plus_long'] = train_data['lat']+train_data['long']\n",
    "test_data['lat_plus_long'] = test_data['lat']+test_data['long']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Squaring bedrooms will increase the separation between not many bedrooms (e.g. 1) and lots of bedrooms (e.g. 4) since \n",
    "$$\n",
    "\\begin{align}\n",
    "1^2 = 1\n",
    "\\end{align}\n",
    "$$\n",
    "but\n",
    "$$\n",
    "\\begin{align}\n",
    "4^2 = 16. \\end{align}\n",
    "$$\n",
    "Consequently this feature will mostly affect houses with many bedrooms.\n",
    "* bedrooms times bathrooms gives what's called an \"interaction\" feature. It is large when *both* of them are large.\n",
    "* Taking the log of squarefeet has the effect of bringing large values closer together and spreading out small values.\n",
    "* Adding latitude to longitude is totally non-sensical but we will do it anyway (you'll see why)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>bedrooms_squared</th>\n",
       "      <th>bed_bath_rooms</th>\n",
       "      <th>log_sqft_living</th>\n",
       "      <th>lat_plus_long</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8028</th>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>47.5950</td>\n",
       "      <td>-122.173</td>\n",
       "      <td>9</td>\n",
       "      <td>7.5</td>\n",
       "      <td>8.185907</td>\n",
       "      <td>-74.5780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11967</th>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>47.5532</td>\n",
       "      <td>-122.280</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.917706</td>\n",
       "      <td>-74.7268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15743</th>\n",
       "      <td>4</td>\n",
       "      <td>1.75</td>\n",
       "      <td>47.6209</td>\n",
       "      <td>-122.302</td>\n",
       "      <td>16</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.791523</td>\n",
       "      <td>-74.6811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5750</th>\n",
       "      <td>5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>47.6605</td>\n",
       "      <td>-122.324</td>\n",
       "      <td>25</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.154615</td>\n",
       "      <td>-74.6635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10630</th>\n",
       "      <td>4</td>\n",
       "      <td>1.50</td>\n",
       "      <td>47.7501</td>\n",
       "      <td>-122.302</td>\n",
       "      <td>16</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.489971</td>\n",
       "      <td>-74.5519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       bedrooms  bathrooms      lat     long  bedrooms_squared  \\\n",
       "8028          3       2.50  47.5950 -122.173                 9   \n",
       "11967         2       1.00  47.5532 -122.280                 4   \n",
       "15743         4       1.75  47.6209 -122.302                16   \n",
       "5750          5       1.00  47.6605 -122.324                25   \n",
       "10630         4       1.50  47.7501 -122.302                16   \n",
       "\n",
       "       bed_bath_rooms  log_sqft_living  lat_plus_long  \n",
       "8028              7.5         8.185907       -74.5780  \n",
       "11967             2.0         6.917706       -74.7268  \n",
       "15743             7.0         7.791523       -74.6811  \n",
       "5750              5.0         7.154615       -74.6635  \n",
       "10630             6.0         7.489971       -74.5519  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[['bedrooms','bathrooms','lat','long','bedrooms_squared','bed_bath_rooms','log_sqft_living','lat_plus_long']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question: What is the mean (arithmetic average) value of your 4 new features on TEST data? (round to 2 digits)**\n",
    "\n",
    "**Answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of TestData---(bedrooms squared: 12\n",
      "Mean of TestData-----(bed bath rooms: 7 \n",
      "Mean of TestData----(log sqft living: 7 \n",
      "Mean of TestData------(lat plus long: -74 \n"
     ]
    }
   ],
   "source": [
    "print('Mean of TestData---(bedrooms squared: %d'%test_data['bedrooms_squared'].mean())\n",
    "print('Mean of TestData-----(bed bath rooms: %d '%test_data['bed_bath_rooms'].mean())\n",
    "print('Mean of TestData----(log sqft living: %d '%test_data['log_sqft_living'].mean())\n",
    "print('Mean of TestData------(lat plus long: %d '%test_data['lat_plus_long'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Multiple Models\n",
    "\n",
    "Now we will learn the weights for three (nested) models for predicting house prices. The first model will have the fewest features the second model will add one more feature and the third will add a few more:\n",
    "* Model 1: squarefeet, # bedrooms, # bathrooms, latitude & longitude\n",
    "* Model 2: add bedrooms\\*bathrooms\n",
    "* Model 3: Add log squarefeet, bedrooms squared, and the (nonsensical) latitude + longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1_features = ['sqft_living', 'bedrooms', 'bathrooms', 'lat', 'long']\n",
    "model_2_features = model_1_features + ['bed_bath_rooms']\n",
    "model_3_features = model_2_features + ['bedrooms_squared', 'log_sqft_living', 'lat_plus_long']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have the features, learn the weights for the three different models for predicting target = 'price' using linear_model.LinearRegression(). and look at the value of the weights/coefficients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Learn the three models: (don't forget to set validation_set = None)\n",
    "# MODEL 1\n",
    "model_1 = linear_model.LinearRegression()\n",
    "model_1.fit(train_data[model_1_features],train_data['price'])\n",
    "\n",
    "# MODEL 2\n",
    "model_2 = linear_model.LinearRegression()\n",
    "model_2.fit(train_data[model_2_features],train_data['price'])\n",
    "\n",
    "# MODEL 3\n",
    "model_3 = linear_model.LinearRegression()\n",
    "model_3.fit(train_data[model_3_features],train_data['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model1 Coeficients:\n",
      "[ 3.08887695e+02 -5.83106922e+04  1.64003544e+04  6.56212809e+05\n",
      " -3.04971323e+05]\n",
      "\n",
      "Model2 Coeficients:\n",
      "[ 3.04530899e+02 -1.02903339e+05 -5.62387893e+04  6.53407715e+05\n",
      " -2.92481427e+05  2.12575454e+04]\n",
      "\n",
      "Model3 Coeficients:\n",
      "[ 5.14465125e+02  2.71898262e+04  8.02273301e+04  5.32003957e+05\n",
      " -4.04032857e+05 -1.23095455e+04 -4.64241039e+03 -5.30058064e+05\n",
      "  1.27971100e+05]\n"
     ]
    }
   ],
   "source": [
    "# Examine/extract each model's coefficients:\n",
    "model_1_weight_summary = model_1.coef_\n",
    "model_2_weight_summary = model_2.coef_\n",
    "model_3_weight_summary = model_3.coef_\n",
    "\n",
    "print('Model1 Coeficients:')\n",
    "print(model_1_weight_summary)\n",
    "\n",
    "print('\\nModel2 Coeficients:')\n",
    "print(model_2_weight_summary)\n",
    "\n",
    "print('\\nModel3 Coeficients:')\n",
    "print(model_3_weight_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question: What is the sign (positive or negative) for the coefficient/weight for 'bathrooms' in model 1?**\n",
    "\n",
    "    **Answer:** Coeficient of 'bathroom' ---> Positive (3th)\n",
    "\n",
    "\n",
    "**Quiz Question: What is the sign (positive or negative) for the coefficient/weight for 'bathrooms' in model 2?**\n",
    "\n",
    "    **Answer:** Negative (3th)\n",
    "\n",
    "Think about what this means."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing multiple models\n",
    "\n",
    "Now that you've learned three models and extracted the model weights we want to evaluate which model is best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First use your functions from earlier to compute the RSS on TRAINING Data for each of the three models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSS Model 1: 940940329132490\n",
      "\n",
      "RSS Model 2: 934349514420330\n",
      "\n",
      "RSS Model 3: 885348573944778\n"
     ]
    }
   ],
   "source": [
    "# Compute the RSS on TRAINING data for each of the three models and record the values:\n",
    "rss_model_1_train = get_residual_sum_of_squares(model_1, train_data, model_1_features, train_data['price'])\n",
    "rss_model_2_train = get_residual_sum_of_squares(model_2, train_data, model_2_features, train_data['price'])\n",
    "rss_model_3_train = get_residual_sum_of_squares(model_3, train_data, model_3_features, train_data['price'])\n",
    "\n",
    "print('RSS Model 1: %d'%(rss_model_1_train))\n",
    "print('\\nRSS Model 2: %d'%(rss_model_2_train))\n",
    "print('\\nRSS Model 3: %d'%(rss_model_3_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question: Which model (1, 2 or 3) has lowest RSS on TRAINING Data?** Is this what you expected?\n",
    "\n",
    "    **Answer:** Model 3 is better than others.\n",
    "\n",
    "&emsp;&emsp;\n",
    "\n",
    "Now compute the RSS on TEST data for each of the three models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSS Model 1: 252310966056068\n",
      "\n",
      "RSS Model 2: 247600046018032\n",
      "\n",
      "RSS Model 3: 255242885877590\n"
     ]
    }
   ],
   "source": [
    "# Compute the RSS on TESTING data for each of the three models and record the values:\n",
    "rss_model_1_test = get_residual_sum_of_squares(model_1, test_data, model_1_features, test_data['price'])\n",
    "rss_model_2_test = get_residual_sum_of_squares(model_2, test_data, model_2_features, test_data['price'])\n",
    "rss_model_3_test = get_residual_sum_of_squares(model_3, test_data, model_3_features, test_data['price'])\n",
    "\n",
    "print('RSS Model 1: %d'%(rss_model_1_test))\n",
    "print('\\nRSS Model 2: %d'%(rss_model_2_test))\n",
    "print('\\nRSS Model 3: %d'%(rss_model_3_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;\n",
    "## Result\n",
    " **Quiz Question: Which model (1, 2 or 3) has lowest RSS on TESTING Data?** Is this what you expected? Think about the features that were added to each model from the previous.\n",
    "\n",
    "* RSS Model-1 on TEST data: 219742130498805\n",
    "* RSS Model-2 on TEST data: 216715801956578\n",
    "* RSS Model-3 on TEST data: 209668128559972\n",
    "\n",
    "The RSS of the Model_3 is the lowest.\n",
    "\n",
    "> #### Model_3 is better than other models.\n",
    "\n",
    "&emsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;&emsp;&emsp;&emsp;\n",
    "# Exercise 1- 2\n",
    "# Regression Week 2: Multiple Regression (gradient descent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first notebook we explored multiple regression using sklearn Create. Now we will use sklearn Create along with numpy to solve for the regression weights with gradient descent.\n",
    "\n",
    "In this notebook we will cover estimating multiple regression weights via gradient descent. You will:\n",
    "* Add a constant column of 1's to a dataframe to account for the intercept\n",
    "* Convert an dataframe into a Numpy array\n",
    "* Write a predict_output() function using Numpy\n",
    "* Write a numpy function to compute the derivative of the regression weights with respect to a single feature\n",
    "* Write gradient descent function to compute the regression weights given an initial weight vector, step size and tolerance.\n",
    "* Use the gradient descent function to estimate regression weights for multiple features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in house sales data\n",
    "\n",
    "Dataset is from house sales in King County, the region where the city of Seattle, WA is located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             date     price  bedrooms  bathrooms  sqft_living  \\\n",
       "0  7129300520  20141013T000000  221900.0         3       1.00         1180   \n",
       "1  6414100192  20141209T000000  538000.0         3       2.25         2570   \n",
       "2  5631500400  20150225T000000  180000.0         2       1.00          770   \n",
       "3  2487200875  20141209T000000  604000.0         4       3.00         1960   \n",
       "4  1954400510  20150218T000000  510000.0         3       2.00         1680   \n",
       "\n",
       "   sqft_lot  floors  waterfront  view     ...      grade  sqft_above  \\\n",
       "0      5650     1.0           0     0     ...          7        1180   \n",
       "1      7242     2.0           0     0     ...          7        2170   \n",
       "2     10000     1.0           0     0     ...          6         770   \n",
       "3      5000     1.0           0     0     ...          7        1050   \n",
       "4      8080     1.0           0     0     ...          8        1680   \n",
       "\n",
       "   sqft_basement  yr_built  yr_renovated  zipcode      lat     long  \\\n",
       "0              0      1955             0    98178  47.5112 -122.257   \n",
       "1            400      1951          1991    98125  47.7210 -122.319   \n",
       "2              0      1933             0    98028  47.7379 -122.233   \n",
       "3            910      1965             0    98136  47.5208 -122.393   \n",
       "4              0      1987             0    98074  47.6168 -122.045   \n",
       "\n",
       "   sqft_living15  sqft_lot15  \n",
       "0           1340        5650  \n",
       "1           1690        7639  \n",
       "2           2720        8062  \n",
       "3           1360        5000  \n",
       "4           1800        7503  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_2 = pd.read_csv(\"data/week2_kc_house_data.csv\")\n",
    "dtype_dict = {'bathrooms':float, 'waterfront':int, 'sqft_above':int, 'sqft_living15':float, 'grade':int, 'yr_renovated':int, 'price':float, 'bedrooms':float, 'zipcode':str, 'long':float, 'sqft_lot15':float, 'sqft_living':float, 'floors':str, 'condition':int, 'lat':float, 'date':str, 'sqft_basement':int, 'yr_built':int, 'id':str, 'sqft_lot':int, 'view':int}\n",
    "\n",
    "sales_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to do any \"feature engineering\" like creating new features or adjusting existing ones we should do this directly using the dataframe as seen in the other Week 2 notebook. For this notebook, however, we will work with the existing features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;\n",
    "# Convert to Numpy Array\n",
    "Although dataframe offer a number of benefits to users (especially when using Big Data and built-in ... Create functions) in order to understand the details of the implementation of algorithms it's important to work with a library that allows for direct (and optimized) matrix operations. Numpy is a Python solution to work with matrices (or any multi-dimensional \"array\").\n",
    "\n",
    "Recall that the predicted value given the weights and the features is just the dot product between the feature and weight vector. Similarly, if we put all of the features row-by-row in a matrix then the predicted value for *all* the observations can be computed by right multiplying the \"feature matrix\" by the \"weight vector\". \n",
    "\n",
    "First we need to take the dataframe of our data and convert it into a 2D numpy array (also called a matrix). To do this we can use Panda's .as_matrix() to convert the dataframe into a numpy matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;\n",
    "\n",
    "Now we will write a function that will accept an Pandas dataframe, a list of feature names (e.g. ['sqft_living', 'bedrooms']) and an target feature e.g. ('price') and will return two things:\n",
    "* A numpy matrix whose columns are the desired features plus a constant column (this is how we create an 'intercept')\n",
    "* A numpy array containing the values of the output\n",
    "\n",
    "With this in mind, complete the following function (where there's an empty line you should write a line of code that does what the comment above indicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numpy_data(dataframe, features, output):\n",
    "    dataframe['constant'] = 1 # this is how you add a constant column to an dataframe\n",
    "    \n",
    "    # add the column 'constant' to the front of the features list so that we can extract it along with the others:\n",
    "    features = ['constant'] + features # this is how you combine two lists\n",
    "    \n",
    "    # select the columns of data given by the features list into the dataframe features_data (now including constant):\n",
    "    features_dataframe = dataframe[features]\n",
    "    \n",
    "    # the following line will convert the features_data into a numpy matrix:\n",
    "    feature_matrix = features_dataframe.as_matrix()\n",
    "    \n",
    "    # assign the column of data associated with the output to the Array output_array\n",
    "    output_dataframe = dataframe[output]\n",
    "    \n",
    "    # the following will convert the Array into a numpy array by first converting it to a list\n",
    "    output_array = output_dataframe.as_matrix()\n",
    "    \n",
    "    return(feature_matrix, output_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For testing let's use the 'sqft_living' feature and a constant as our features and price as our output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example_features: \n",
      "[   1 1180]\n",
      "\n",
      "Example_output: \n",
      "221900.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "(example_features, example_output) = get_numpy_data(sales_2, ['sqft_living'], 'price') # the [] around 'sqft_living' makes it a list\n",
    "\n",
    "print(\"Example_features: \")\n",
    "print(example_features[0,:]) # this accesses the first row of the data the ':' indicates 'all columns'\n",
    "print(\"\\nExample_output: \")\n",
    "print(example_output[0]) # and the corresponding output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting output given regression weights\n",
    "Suppose we had the weights [1.0, 1.0] and the features [1.0, 1180.0] and we wanted to compute the predicted output \n",
    "$$\n",
    "\\begin{align}\n",
    "1.0*1.0 + 1.0*1180.0 = 1181.0 \n",
    "\\end{align}\n",
    "$$\n",
    "this is the dot product between these two arrays. If they're numpy arrayws we can use np.dot() to compute this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Value: 1181\n"
     ]
    }
   ],
   "source": [
    "my_weights = np.array([1., 1.])    # the example weights\n",
    "my_features = example_features[0,] # we'll use the first data point\n",
    "predicted_value = np.dot(my_features, my_weights)\n",
    "\n",
    "print(\"Predicted Value: %d\"%(predicted_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.dot() also works when dealing with a matrix and a vector. Recall that the predictions from all the observations is just the RIGHT (as in weights on the right) dot product between the features *matrix* and the weights *vector*. With this in mind finish the following predict_output function to compute the predictions for an entire matrix of features given the matrix and the weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_output(feature_matrix, weights):\n",
    "    # assume feature_matrix is a numpy matrix containing the features as columns and weights is a corresponding numpy array\n",
    "    # create the predictions vector by using np.dot()\n",
    "    predictions = np.dot(feature_matrix, weights)\n",
    "\n",
    "    return(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to test your code run the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_prediction[0]: 1181\n",
      "Test_prediction[1]: 2571\n"
     ]
    }
   ],
   "source": [
    "test_predictions = predict_output(example_features, my_weights)\n",
    "\n",
    "print(\"Test_prediction[0]: %d\"%(test_predictions[0])) # should be 1181.0\n",
    "print(\"Test_prediction[1]: %d\"%(test_predictions[1])) # should be 2571.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing the Derivative\n",
    "We are now going to move to computing the derivative of the regression cost function. Recall that the cost function is the sum over the data points of the squared difference between an observed output and a predicted output.\n",
    "\n",
    "Since the derivative of a sum is the sum of the derivatives we can compute the derivative for a single data point and then sum over data points. We can write the squared difference between the observed output and predicted output for a single point as follows:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "(w[0]*[CONSTANT] + w[1]*[feature_1] + ... + w[i] *[feature_i] + ... +  w[k]*[feature_k] - output)^2\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Where we have k features and a constant. So the derivative with respect to weight w[i] by the chain rule is:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "2*(w[0]*[CONSTANT] + w[1]*[feature_1] + ... + w[i] *[feature_i] + ... +  w[k]*[feature_k] - output)* [feature_i]\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "The term inside the paranethesis is just the error (difference between prediction and output). So we can re-write this as:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "2*error*[feature_i]\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "That is, the derivative for the weight for feature i is the sum (over data points) of 2 times the product of the error and the feature itself. In the case of the constant then this is just twice the sum of the errors!\n",
    "\n",
    "Recall that twice the sum of the product of two vectors is just twice the dot product of the two vectors. Therefore the derivative for the weight for feature_i is just two times the dot product between the values of feature_i and the current errors. \n",
    "\n",
    "With this in mind complete the following derivative function which computes the derivative of the weight given the value of the feature (over all data points) and the errors (over all data points)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_derivative(errors, feature):\n",
    "    # Assume that errors and feature are both numpy arrays of the same length (number of data points)\n",
    "    # compute twice the dot product of these vectors as 'derivative' and return the value\n",
    "    derivative = 2*np.dot(errors, feature)\n",
    "    return(derivative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test your feature derivartive run the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-23345850016.0\n",
      "-23345850016.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "(example_features, example_output) = get_numpy_data(sales, ['sqft_living'], 'price') \n",
    "my_weights = np.array([0., 0.]) # this makes all the predictions 0\n",
    "test_predictions = predict_output(example_features, my_weights) \n",
    "# just like dataframes 2 numpy arrays can be elementwise subtracted with '-': \n",
    "errors = test_predictions - example_output # prediction errors in this case is just the -example_output\n",
    "feature = example_features[:,0] # let's compute the derivative with respect to 'constant', the \":\" indicates \"all rows\"\n",
    "derivative = feature_derivative(errors, feature)\n",
    "\n",
    "print(derivative)\n",
    "print(-np.sum(example_output)*2) # should be the same as derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent\n",
    "Now we will write a function that performs a gradient descent. The basic premise is simple. Given a starting point we update the current weights by moving in the negative gradient direction. Recall that the gradient is the direction of *increase* and therefore the negative gradient is the direction of *decrease* and we're trying to *minimize* a cost function. \n",
    "\n",
    "The amount by which we move in the negative gradient *direction*  is called the 'step size'. We stop when we are 'sufficiently close' to the optimum. We define this by requiring that the magnitude (length) of the gradient vector to be smaller than a fixed 'tolerance'.\n",
    "\n",
    "With this in mind, complete the following gradient descent function below using your derivative function above. For each step in the gradient descent we update the weight for each feature befofe computing our stopping criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt # recall that the magnitude/length of a vector [g[0], g[1], g[2]] is sqrt(g[0]^2 + g[1]^2 + g[2]^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_gradient_descent(feature_matrix, output, initial_weights, step_size, tolerance):\n",
    "    converged = False \n",
    "    weights = np.array(initial_weights) # make sure it's a numpy array\n",
    "    while not converged:\n",
    "        # compute the predictions based on feature_matrix and weights using your predict_output() function\n",
    "        predictions = predict_output(feature_matrix, weights)\n",
    "\n",
    "        # compute the errors as predictions - output\n",
    "        errors = predictions - output\n",
    "\n",
    "        gradient_sum_squares = 0 # initialize the gradient sum of squares\n",
    "        # while we haven't reached the tolerance yet, update each feature's weight\n",
    "        for i in range(len(weights)): # loop over each weight\n",
    "            # Recall that feature_matrix[:, i] is the feature column associated with weights[i]\n",
    "            # compute the derivative for weight[i]:\n",
    "            derivative = feature_derivative(errors, feature_matrix[:, i])\n",
    "\n",
    "            # add the squared value of the derivative to the gradient sum of squares (for assessing convergence)\n",
    "            gradient_sum_squares += (derivative**2)\n",
    "\n",
    "            # subtract the step size times the derivative from the current weight\n",
    "            weights[i] -= (step_size * derivative)\n",
    "            \n",
    "        # compute the square-root of the gradient sum of squares to get the gradient magnitude:\n",
    "        gradient_magnitude = sqrt(gradient_sum_squares)\n",
    "        if gradient_magnitude < tolerance:\n",
    "            converged = True\n",
    "    return(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few things to note before we run the gradient descent. Since the gradient is a sum over all the data points and involves a product of an error and a feature the gradient itself will be very large since the features are large (squarefeet) and the output is large (prices). So while you might expect \"tolerance\" to be small, small is only relative to the size of the features. \n",
    "\n",
    "For similar reasons the step size will be much smaller than you might expect but this is because the gradient has such large values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the Gradient Descent as Simple Regression\n",
    "First let's split the data into training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,test_data = train_test_split(sales_2,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the gradient descent is designed for multiple regression since the constant is now a feature we can use the gradient descent function to estimate the parameters in the simple regression on squarefeet. The folowing cell sets up the feature_matrix, output, initial weights and step size for the first model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "# let's test out the gradient descent\n",
    "simple_features = ['sqft_living']\n",
    "my_output = 'price'\n",
    "\n",
    "(simple_feature_matrix, output) = get_numpy_data(train_data, simple_features, my_output)\n",
    "\n",
    "initial_weights = np.array([-47000., 1.])\n",
    "step_size = 7e-12\n",
    "tolerance = 2.5e7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next run your gradient descent with the above parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-46999.88427043    282.48042519]\n"
     ]
    }
   ],
   "source": [
    "test_weight = regression_gradient_descent(simple_feature_matrix, output, initial_weights, step_size, tolerance)\n",
    "\n",
    "print(test_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do your weights compare to those achieved in week 1 (don't expect them to be exactly the same)? \n",
    "\n",
    "**Quiz Question: What is the value of the weight for sqft_living -- the second element of ‘simple_weights’ (rounded to 1 decimal place)?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use your newly estimated weights and your predict_output() function to compute the predictions on all the TEST data (you will need to create a numpy array of the test feature_matrix and test output first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "(test_simple_feature_matrix, test_output) = get_numpy_data(test_data, simple_features, my_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compute your predictions using test_simple_feature_matrix and your weights from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[306100.64722172 871061.49760915 534909.79162863 ... 458640.07682632\n",
      " 667675.59146968 362596.73226046]\n"
     ]
    }
   ],
   "source": [
    "test_predictions = predict_output(test_simple_feature_matrix, test_weight)\n",
    "\n",
    "print(test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question: What is the predicted price for the 1st house in the TEST data set for model 1 (round to nearest dollar)?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "306100.6472217162\n"
     ]
    }
   ],
   "source": [
    "print(test_predictions[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have the predictions on test data, compute the RSS on the test data set. Save this value for comparison later. Recall that RSS is the sum of the squared errors (difference between prediction and output)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291220853705378.5\n"
     ]
    }
   ],
   "source": [
    "test_residuals = test_output - test_predictions\n",
    "test_RSS = (test_residuals * test_residuals).sum()\n",
    "\n",
    "print(test_RSS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running a multiple regression\n",
    "Now we will use more than one actual feature. Use the following code to produce the weights for a second model with the following parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "model_features = ['sqft_living', 'sqft_living15'] # sqft_living15 is the average squarefeet for the nearest 15 neighbors. \n",
    "my_output = 'price'\n",
    "(feature_matrix, output) = get_numpy_data(train_data, model_features, my_output)\n",
    "initial_weights = np.array([-100000., 1., 1.])\n",
    "step_size = 4e-12\n",
    "tolerance = 1e9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the above parameters to estimate the model weights. Record these values for your quiz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-9.99999546e+04  2.42341529e+02  6.88997536e+01]\n"
     ]
    }
   ],
   "source": [
    "weight_2 = regression_gradient_descent(feature_matrix, output, initial_weights, step_size, tolerance)\n",
    "\n",
    "print(weight_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use your newly estimated weights and the predict_output function to compute the predictions on the TEST data. Don't forget to create a numpy array for these features from the test set first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[280783.67886893 891553.28695681 526688.14035549 ... 453676.95449708\n",
      " 670215.55326846 351299.90592349]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:17: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "(test_feature_matrix, test_output) = get_numpy_data(test_data, model_features, my_output)\n",
    "\n",
    "test_predictions_2 = predict_output(test_feature_matrix, weight_2)\n",
    "\n",
    "print(test_predictions_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question: What is the predicted price for the 1st house in the TEST data set for model 2 (round to nearest dollar)?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280783.67886893265\n"
     ]
    }
   ],
   "source": [
    "print(test_predictions_2[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the actual price for the 1st house in the test data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155000.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(test_data['price'][0])\n",
    "test_data['price'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz Question: Which estimate was closer to the true price for the 1st house on the TEST data set, model 1 or model 2?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use your predictions and the output to compute the RSS for model 2 on TEST data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287039655170051.94\n"
     ]
    }
   ],
   "source": [
    "test_residuals_2 = test_output - test_predictions_2\n",
    "test_RSS_2 = (test_residuals_2**2).sum()\n",
    "\n",
    "print(test_RSS_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&emsp;\n",
    "## Result\n",
    " **Quiz Question: Which model (1 or 2) has lowest RSS on all of the TEST data? **\n",
    "* RSS Model-1 on TEST data: 930653102866614\n",
    "* RSS Model-2 on TEST data: 329573350672128\n",
    "\n",
    "The RSS of the Model_2 is lower than the Model_1.\n",
    "\n",
    "> #### Model_2 is the better model.\n",
    "\n",
    "&emsp;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
